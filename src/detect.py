#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import cv2  # OpenCV ‚Äî –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
import torch  # PyTorch ‚Äî –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
import numpy as np  # NumPy ‚Äî –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∞—Å—Å–∏–≤–∞–º–∏ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è = –º–∞—Å—Å–∏–≤—ã —á–∏—Å–µ–ª)
from loguru import logger  # Loguru ‚Äî –∫—Ä–∞—Å–∏–≤—ã–µ –ª–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –∏–∑ YOLOX
from yolox.exp import get_exp  # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
from yolox.utils import postprocess  # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏


# ============================================================
# –ö–õ–ê–°–° –î–ï–¢–ï–ö–¢–û–†–ê
# ============================================================

class YOLOXDetector:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é YOLOX.

    –ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
    - –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å YOLOX
    - –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–¥—Ä—ã —Å –∫–∞–º–µ—Ä—ã
    - –†–∏—Å—É–µ—Ç bounding boxes –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    """

    def __init__(
            self,
            model_name: str = "yolox-nano",  # –ò–º—è –º–æ–¥–µ–ª–∏ (nano ‚Äî —Å–∞–º–∞—è –ª–µ–≥–∫–∞—è)
            conf_threshold: float = 0.5,  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (50%)
            device: str = "cpu"  # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu –∏–ª–∏ cuda)
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ YOLOX (nano/tiny/s/m/l/x)
            conf_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ (0.0-1.0)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π ("cpu" –∏–ª–∏ "cuda")
        """

        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è YOLOX –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.conf_threshold = conf_threshold
        self.device = device

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
        # get_exp() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —Ä–∞–∑–º–µ—Ä—ã –∏ —Ç.–¥.)
        self.exp = get_exp(None, model_name)

        # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.model = self.exp.get_model()

        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º inference (–Ω–µ –æ–±—É—á–µ–Ω–∏–µ)
        self.model.eval()

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU)
        self.model.to(device)

        # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ (–æ–±—ã—á–Ω–æ 416x416 –∏–ª–∏ 640x640)
        self.input_size = (self.exp.test_size[0], self.exp.test_size[1])

        logger.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        logger.info(f"üìè –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞: {self.input_size}")
        logger.info(f"üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {conf_threshold}")

    def preprocess(self, img: np.ndarray) -> torch.Tensor:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å.

        –ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
        1. –ò–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π (0-255 ‚Üí 0-1)
        3. –ú–µ–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ (BGR ‚Üí RGB)
        4. –î–æ–±–∞–≤–ª—è–µ—Ç batch dimension

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (numpy array, BGR, 0-255)

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            –¢–µ–Ω–∑–æ—Ä PyTorch –≥–æ—Ç–æ–≤—ã–π –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å
        """

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        # cv2.resize() –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_resized = cv2.resize(img, self.input_size)

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º BGR (—Ñ–æ—Ä–º–∞—Ç OpenCV) –≤ RGB (—Ñ–æ—Ä–º–∞—Ç PyTorch)
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –¥–µ–ª–∏–º –Ω–∞ 255, —á—Ç–æ–±—ã –∑–Ω–∞—á–µ–Ω–∏—è –±—ã–ª–∏ –æ—Ç 0 –¥–æ 1
        img_normalized = img_rgb.astype(np.float32) / 255.0

        # –ú–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π: (Height, Width, Channels) ‚Üí (Channels, Height, Width)
        # PyTorch —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ñ–æ—Ä–º–∞—Ç–æ–º CHW, –∞ OpenCV ‚Äî —Å HWC
        img_transposed = np.transpose(img_normalized, (2, 0, 1))

        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension: (C, H, W) ‚Üí (1, C, H, W)
        # "1" –æ–∑–Ω–∞—á–∞–µ—Ç batch_size=1 (–æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
        img_tensor = torch.from_numpy(img_transposed).unsqueeze(0)

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Ç–µ–Ω–∑–æ—Ä –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU/GPU)
        img_tensor = img_tensor.to(self.device)

        return img_tensor

    def detect(self, img: np.ndarray):
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (numpy array)

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            outputs: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, –∫–ª–∞—Å—Å—ã, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """

        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_height, img_width = img.shape[:2]

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_tensor = self.preprocess(img)

        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª—å (inference)
        # torch.no_grad() –æ—Ç–∫–ª—é—á–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (—ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å)
        with torch.no_grad():
            outputs = self.model(img_tensor)

        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏
        # postprocess() —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        # –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç Non-Maximum Suppression (NMS)
        outputs = postprocess(
            outputs,
            num_classes=self.exp.num_classes,
            conf_thre=self.conf_threshold,
            nms_thre=0.45  # –ü–æ—Ä–æ–≥ NMS (—É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è bbox)
        )

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
        if outputs[0] is None:
            return None

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox –∫ —Ä–∞–∑–º–µ—Ä—É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # ratio = (—à–∏—Ä–∏–Ω–∞_–∏—Å—Ö–æ–¥–Ω–æ–≥–æ / —à–∏—Ä–∏–Ω–∞_–º–æ–¥–µ–ª–∏, –≤—ã—Å–æ—Ç–∞_–∏—Å—Ö–æ–¥–Ω–æ–≥–æ / –≤—ã—Å–æ—Ç–∞_–º–æ–¥–µ–ª–∏)
        ratio = min(self.input_size[0] / img_width, self.input_size[1] / img_height)
        outputs[0][:, :4] /= ratio

        return outputs[0].cpu().numpy()  # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ CPU –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy

    def draw_boxes(self, img: np.ndarray, detections: np.ndarray) -> np.ndarray:
        """
        –†–∏—Å—É–µ—Ç bounding boxes –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            detections: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ [x1, y1, x2, y2, conf, cls]

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ boxes
        """

        # –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if detections is None:
            return img

        # –ü—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ –∫–∞–∂–¥–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏
        for detection in detections:
            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            x1, y1, x2, y2 = detection[:4].astype(int)  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
            confidence = detection[4]  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            class_id = int(detection[5])  # ID –∫–ª–∞—Å—Å–∞ –æ–±—ä–µ–∫—Ç–∞

            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ (–∑–µ–ª–µ–Ω—ã–π —Ü–≤–µ—Ç, —Ç–æ–ª—â–∏–Ω–∞ 2 –ø–∏–∫—Å–µ–ª—è)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –∏–º–µ–Ω–µ–º –∫–ª–∞—Å—Å–∞ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            label = f"Class {class_id}: {confidence:.2f}"

            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞–¥ bbox
            cv2.putText(
                img, label,
                (x1, y1 - 10),  # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–¥ bbox)
                cv2.FONT_HERSHEY_SIMPLEX,  # –®—Ä–∏—Ñ—Ç
                0.5,  # –†–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
                (0, 255, 0),  # –¶–≤–µ—Ç (–∑–µ–ª–µ–Ω—ã–π)
                2  # –¢–æ–ª—â–∏–Ω–∞
            )

        return img


# ============================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================

def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –∑–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –Ω–∞ –≤–µ–±-–∫–∞–º–µ—Ä–µ.
    """

    logger.info("=" * 60)
    logger.info("üé• –û–ö–û-–°–µ—Ä–≤–∏—Å: –î–µ—Ç–µ–∫—Ç–æ—Ä –û–±—ä–µ–∫—Ç–æ–≤")
    logger.info("=" * 60)

    # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
    detector = YOLOXDetector(
        model_name="yolox-nano",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º nano (—Å–∞–º–∞—è –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å)
        conf_threshold=0.5,  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ 50%
        device="cpu"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU (–¥–ª—è RPi —Ç–æ–∂–µ CPU)
    )

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–µ–±-–∫–∞–º–µ—Ä—É (0 = –ø–µ—Ä–≤–∞—è –∫–∞–º–µ—Ä–∞, 1 = –≤—Ç–æ—Ä–∞—è –∏ —Ç.–¥.)
    logger.info("üìπ –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–µ–±-–∫–∞–º–µ—Ä—É...")
    cap = cv2.VideoCapture(0)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞–º–µ—Ä–∞ –æ—Ç–∫—Ä—ã–ª–∞—Å—å
    if not cap.isOpened():
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É!")
        return

    logger.success("‚úÖ –ö–∞–º–µ—Ä–∞ –æ—Ç–∫—Ä—ã—Ç–∞!")
    logger.info("üí° –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")

    # –°—á—ë—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤ (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è FPS)
    frame_count = 0

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤
    while True:
        # –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã
        ret, frame = cap.read()

        # –ï—Å–ª–∏ –∫–∞–¥—Ä –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–ª—Å—è, –≤—ã—Ö–æ–¥–∏–º
        if not ret:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä")
            break

        # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é
        detections = detector.detect(frame)

        # –†–∏—Å—É–µ–º boxes –Ω–∞ –∫–∞–¥—Ä–µ
        frame_with_boxes = detector.draw_boxes(frame, detections)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        num_detections = 0 if detections is None else len(detections)
        info_text = f"Detections: {num_detections} | Press 'q' to quit"

        cv2.putText(
            frame_with_boxes, info_text,
            (10, 30),  # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª)
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,  # –†–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
            (0, 255, 255),  # –¶–≤–µ—Ç (–∂–µ–ª—Ç—ã–π)
            2  # –¢–æ–ª—â–∏–Ω–∞
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–¥—Ä –≤ –æ–∫–Ω–µ
        cv2.imshow("OKO-Service: YOLOX Detection", frame_with_boxes)

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤
        frame_count += 1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∂–∞—Ç–∏–µ –∫–ª–∞–≤–∏—à–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞
        if cv2.waitKey(1) & 0xFF == ord('q'):
            logger.info("üëã –í—ã—Ö–æ–¥...")
            break

    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
    cap.release()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–∞–º–µ—Ä—É
    cv2.destroyAllWindows()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –æ–∫–Ω–∞ OpenCV

    logger.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_count}")
    logger.info("=" * 60)


# ============================================================
# –¢–û–ß–ö–ê –í–•–û–î–ê
# ============================================================

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    main()